{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to hydrographs, chemographs, concentrations, and loads\n",
    "\n",
    "At the end of this lab, you should be able to:\n",
    "\n",
    "- Recognize a hydrograph and name its descriptors\n",
    "- Calculate cumulative flow volumes \n",
    "- Construct flow duration curves and compare them between small and large watersheds\n",
    "- Recognize a chemograph and define its descriptors\n",
    "- Summarize what the arithmetic average and median concentrations are for common pollutants in mostly agricultural watersheds\n",
    "- Calculate cumulative loads at the event and yearly scale\n",
    "- Distinguish between arithmetic and flow weighted concentrations for a variety of common pollutants in mostly agricultural watersheds\n",
    "- Recognize the importance of high flows to the export of pollutants in watersheds\n",
    "\n",
    "</br></br>\n",
    "\n",
    "## Hydrographs as the basic hydrologist tool\n",
    "\n",
    "In hydrology, we work with time series of flow rates and concentrations, and many of the conclusions we make are based on the calculations of water and nutrient fluxes. The title of this paragraph is time series. Indeed, in hydrology we measure flow not on a continuous basis, but rather at a given frequency. In hydrology, we have been able to make measurements at a high frequency (hourly or smaller), for over 100 years. From this high frequency data, it is possible to obtain a visual representation of the variations of flow. \n",
    "\n",
    "The first example below is an example of what we refer to as a simple hydrograph, which follows a rainfall event, with an initial baseflow, a rapidly rising limb, a flow peak, and a more slowly falling limb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydgph<-read.csv(file = \"hydgph.csv\", header = TRUE)\n",
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "names(hydgph)=c(\"date\",\"Q\",\"NO3\")\n",
    "date=as.POSIXct(hydgph$date, format = \"%Y-%m-%d %H:%M:%S\") # transforms the first column of the file, which are characters into dates that R understands\n",
    "Q=hydgph$Q*1000 # Puts in the variable Q the flow rates, which are orginally in mÂ³/s to L/s for better visualization\n",
    "par(mar=c(4.5,4.5,0.5,0.5))\n",
    "xlimHG=as.POSIXct(c(\"1999-01-03 00:00:00\",\"1999-01-08 00:00:00\"));ylimHG=c(50,350) # this defines the plotting ranges for the x and y axes\n",
    "plot(date,Q,xlab = \"date\",ylab = \"Flow rate (L/s)\",type = \"p\",col=\"blue\",xlim=xlimHG,ylim=ylimHG) # this plots the hydrograph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Although the points are disjointed, it is very tempting to add a line between them, as our observations and intuitions tell us that there is a pattern of flow up or down, and in this example, the time interval between consecutive values is 600 seconds or 10 min. And indeed, this is exactly what people do, we add lines between points as an approximation of what flow must have looked like during the measurement intervals. The same data plotted without the measurement points looks like the figure below, appears *continuous*, although it is not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  library(shape)\n",
    "  par(mar=c(4.5,4.5,0.5,0.5))\n",
    "  options(repr.plot.width=12, repr.plot.height=8)\n",
    "  transpred <- rgb(250, 0, 0, max = 255, alpha = 25) # this defines the color of the transparent color of the pinkish rectangle\n",
    "  transpblue <- rgb(0, 0, 250, max = 255, alpha = 25) # this defines the color of the transparent color of the red rectangle\n",
    "  xlimHG=as.POSIXct(c(\"1999-01-03 00:00:00\",\"1999-01-08 00:00:00\"));ylimHG=c(50,350) # this defines the plotting ranges for the x and y axes\n",
    "  flowpeak<-max(Q) # this calculates the flow rate at the peak\n",
    "  peaktime<-as.POSIXct(date[which(Q==max(Q))]) # this returns date for the peaktime. The function which(Q==max(Q)) is used to return the row number corresponding to when Q is maximum\n",
    "  HGbegtime<-as.POSIXct(\"1999-01-03 7:30:00\") # this defines the date for the beginning of the hydrograph\n",
    "  HGendtime<-as.POSIXct(\"1999-01-08 00:00:00\") # this defines the date for the end of the hydrograph\n",
    "  \n",
    "  plot(date,Q,xlab = \"date\",ylab = \"Flow rate (L/s)\",type = \"l\",col=\"blue\",xlim=xlimHG,ylim=ylimHG) # this plots the hydrograph\n",
    "  rect(as.numeric(HGbegtime),0,as.numeric(peaktime),400,col = transpred) # this plots the red rectangle highlighting the period of rising limb\n",
    "  rect(as.numeric(peaktime),0,as.numeric(HGendtime),400,col = transpblue) # this plots the blue rectangle highlighting the period of falling limb\n",
    "  par(new=TRUE) # this says that we are plotting additional time series onto the existing plot. Without par(new=TRUE), the previous plot would be overwritten\n",
    "  \n",
    "  plot(date,Q,xlab = \"date\",ylab = \"Flow rate (L/s)\",type = \"l\",col=\"blue\",xlim=xlimHG,ylim=ylimHG) # plotting the same plot so that it be on top of the rectangles\n",
    "  text((as.numeric(HGbegtime)+as.numeric(peaktime))/2,200,\"Rising limb\", col = \"red\",srt = 90) # adds the text \"rising limb\" at the right spot inside the red rectangle\n",
    "  text((as.numeric(peaktime)+as.numeric(HGendtime))/2,200,\"Falling limb\", col = \"blue\") # adds the text \"falling limb\" at the right spot inside the blue rectangle\n",
    "  Arrows(as.numeric(HGbegtime),100, as.numeric(peaktime),100, arr.adj = 1, code=3) # adds a double sided arrow in the rising limb phase\n",
    "  text((as.numeric(peaktime)+as.numeric(HGbegtime))/2,120,\"Time of rise\") # adds text above the double sided arrow in the rising limb phase\n",
    "  Arrows(as.numeric(peaktime)+24*60*60,flowpeak, as.numeric(peaktime),flowpeak, arr.adj = 1, code=2) # adds a single sided arrow to show the peak\n",
    "  text(as.numeric(peaktime)+27*60*60,flowpeak,paste0(\"Flow peak = \",signif(flowpeak,digits = 3),\" L/s\"),adj = c(0,0.5)) # adds the text with automatic writing of the peak flow rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of a hydrograph\n",
    "  \n",
    "  A hydrograph is characterized by a ***fast rising limb***, and a ***slower falling limb***. This is the typical response of flow following a rainfall event. The time it takes to go from the beginning of what we refer to as ***an event*** to the peak is called ***time of rise***. The maximum of the flow rate is referred to as ***peakflow***.\n",
    "  \n",
    "### Actual hydrograph over an entire year\n",
    "  \n",
    "  The goal of the first part above was to realize that there is no such thing as *continuous data*, but that really all data around the world is an assemblage of discontinuous data points. In the case of hydrological data, all points are auto-correlated, and provided that flow be measured frequently enough, then a linear interpolation between consecutive points is just fine. \n",
    "  \n",
    "  Now, let us explore what a typical yearly hydrograph of a watershed in a temperate climate where snow does not play a significant role. The conventional acronym for flow rates is the letter *Q*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  data<-read.csv(file=\"sample_1hr_QC_data.csv\",header = TRUE) #Reads file into table format\n",
    "  options(repr.plot.width=12, repr.plot.height=8)\n",
    "  WSarea<-24.2 #Area of watershed in km2\n",
    "  WS<-\"Maudouve at Saint-Donan, France\"\n",
    "  names(data)=c(\"datetime\",\"Q\",\"C\")   # renames the columns in simpler names\n",
    "  data<-as.data.frame(data)\n",
    "  data$datetime<-as.POSIXct(strptime(data$datetime, \"%Y-%m-%d %H:%M:%S\")) # transforms characters into date values understood by R\n",
    "  D<-data$datetime\n",
    "  Q<-data$Q   #Defines Q as the flow value (m3/s)\n",
    "  \n",
    "  N=nrow(data)   #Sets N to the value equal to the number of total rows in the table\n",
    "  \n",
    "  # definition of the x and y axes limits\n",
    "  \n",
    "  startdate<-D[1]\n",
    "  enddate<-D[N]\n",
    "  xlim = as.POSIXct(c(startdate,enddate))  # this renders the first and last date understandable for plotting purposes\n",
    "  ylimQ = c(0,max(Q))           # ylim for flow\n",
    "      \n",
    "  ScaleF = 1.2                  # scaling factor for size of fonts and other things\n",
    "      \n",
    "  y1lab<-expression(\"Flow rate (\" * m^3 * \"/s)\")  # defines the label for flow\n",
    "  \n",
    "  par(mar=c(4.5,4.5,4,4.5))     # defines the sizes, in number of lines, for the margins (bottom, left, top, right)\n",
    "  \n",
    "      ltyp=c(1,2)\n",
    "      \n",
    "      plot(D,Q,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=xlim,ylim=ylimQ)\n",
    "      # we are taking all the default addition of axis tick marks and numbers out by using xaxt and yaxt = \"n\"\n",
    "      # and setting the axis labels at nothing using xlab = \"\" and ylab = \"\"\n",
    "      abline(h=0)\n",
    "      abline(v=seq(startdate, enddate, by=\"week\"),col=(\"grey\"))\n",
    "      axis.POSIXct(1, at=seq(startdate, enddate, by=\"month\"), format=\"%m/%d\",cex.axis=ScaleF)\n",
    "      # this tells R that we want the X axis ticks and values to be displayed as dates, be added on a monthly basis,\n",
    "      # using the month/day format\n",
    "      axis(2,cex.axis=ScaleF)\n",
    "      # this tells R that the first Y axis ticks can be displayed  (that function was repressed earlier by 'yaxt=\"n\" ')\n",
    "      par(new=TRUE)\n",
    "      # this tells R that a new plot has already been opened, in other words you are telling R to keep adding things\n",
    "      # on the existing plot\n",
    "      \n",
    "      mtext(\"Dates in 1997-1998\",side=1,line=3,cex=ScaleF) # add in the margin the defined labels and title\n",
    "      mtext(y1lab,side=2,line=3,cex=ScaleF)\n",
    "      mtext(WS,side=3,line=1.5,cex=ScaleF)\n",
    "      \n",
    "      legend(\"topleft\",c(\"Flow\"),lty = c(1), col = c(\"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notice that one can see individual hydrographs characterized for the rapid rise of flow rates, followed by a rapid fall. But they seem to occur *on top* of a transient minimum flow rate. The latter is called ***baseflow***. It corresponds to the stream water exclusively fed by groundwater. You can see in this example that there is very low baseflow from September 1^st^ to the 3^rd^ week of October. A large event around that time raises the baseflow to about 250 L/s and this stays almost stable until the end of the third week of December. This is the time when most of the rainfall starts in this part of the world and heavy rainfall last until the middle of January. The baseflow during these 1.5 months rose above 600 L/s. It took about an entire month with nearly no rainfall from the last week of January to the last week of Febraury for baseflow to go down to the pre-December values. Baseflow stays at that general level between the last week of February to the first week of April. Then a series of large rainfall events raise the baseflow back to high levels throughout the month of April. Again, it takes again about one month for baseflow to decrease and then stay stable throughout the month of June. In July and August, even a relative large event at the end of the first week of July does not raise the baseflow level, which steadily disminishes until the beginning of September.\n",
    " \n",
    " ### Calculating water fluxes or cumulative flow volumes\n",
    "  \n",
    "  Flow peaks matter very much for flooding issues and an entire domain of hydrology and statistical hydrology is devoted to calculating and predicting flow peaks generating floods. For water quality purposes, flow volumes matter just as much as flow peaks do. Indeed, the amount or load of pollutants leaving a field or a watershed, or delivered in a receiving water body, depends on the total volume of water, and, on the concentrations.\n",
    "  \n",
    "  Flow volumes or cumulative flows, correspond to the cumulative volume of water that has passed at a particular point over a given period. Mathematically, this means that flow volumes correspond to the integral over time of the instantaneous flow rates. or \n",
    "  \n",
    "\n",
    "  $CumulQ = \\int_{}^{period}{Q(t).dt}$\n",
    "\n",
    "  \n",
    "  In practice, because the instantaneous flow rates are discrete in time, \n",
    "  \n",
    "\n",
    "$CumulQ = \\sum_{i=1}^{n-1}{\\frac{(Q_i + Q_{i+1})}{2}}.time \\space interval$\n",
    "\n",
    "  \n",
    "  If we zoom on a hypothetical hydrograph with 5 measurement points, this corresponds to cumulating the area under each trapeze represented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=12)  \n",
    "par(mfrow = c(3,2));par(mar=c(4.5,5,0.5,0.5))   \n",
    "  x<-0:5\n",
    "  TS<-c(0,1,2,3,4,5)\n",
    "  time_interval=1 \n",
    "  xlim=c(0,7)\n",
    "  ylim=c(0,6)\n",
    "  \n",
    "  # First plot: hydrograph\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim,xlab = 'time (hr)',ylab = 'Q (L/hr)')\n",
    "\n",
    "  # Second plot: hydrograph + area under the curve\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim,xlab = 'time (hr)',ylab = 'Q (L/hr)')\n",
    "  polygx<-cbind(head(x,-1),head(x,-1),x[-1],x[-1],head(x,-1))         # x values of the polygons\n",
    "  polygy<-cbind(rep(0,length(TS)-1),head(TS,-1),TS[-1],rep(0,length(TS)-1),rep(0,length(TS)-1))   # y values of the polygons\n",
    "  for (j in 1:(length(TS)-1)){polygon((as.vector(polygx[j,])),as.vector(polygy[j,]),col=\"lightblue\")}\n",
    "  par(new=TRUE)\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim,xlab=\"\",ylab=\"\",xaxt=\"n\",yaxt=\"n\")     \n",
    "  \n",
    "  # Third plot: hydrograph + step area under the curve\n",
    "  suprectxy=cbind(0:4,rep(0,5),1:5,TS[2:6])\n",
    "  infrectxy=cbind(0:4,rep(0,5),1:5,TS[1:5])\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim,xlab = 'time (hr)',ylab = 'Q (L/hr)')\n",
    "  for (i in 1:5){rect(infrectxy[i,1],infrectxy[i,2],infrectxy[i,3],infrectxy[i,4],col = transpblue)}\n",
    "  par(new=TRUE)\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim,xlab=\"\",ylab=\"\",xaxt=\"n\",yaxt=\"n\")     \n",
    "  \n",
    "  # Fourth plot: hydrograph + step area above the curve\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim,xlab = 'time (hr)',ylab = 'Q (L/hr)')\n",
    "  for (i in 1:5){rect(suprectxy[i,1],suprectxy[i,2],suprectxy[i,3],suprectxy[i,4],col = transpred)}\n",
    "  par(new=TRUE)\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim,xlab=\"\",ylab=\"\",xaxt=\"n\",yaxt=\"n\")     \n",
    "  \n",
    "  # Fifth plot: hydrograph + step area above the curve\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim,xlab = 'time (hr)',ylab = 'Q (L/hr)')\n",
    "  for (i in 1:5){rect(infrectxy[i,1],infrectxy[i,2],infrectxy[i,3],infrectxy[i,4],col = transpblue)}\n",
    "  for (i in 1:5){rect(suprectxy[i,1],suprectxy[i,2],suprectxy[i,3],suprectxy[i,4],col = transpred)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  One could calculate the cumulative flow by adding over time the area under each trapeze at in the example below. The result of this mock unitless 'hydrograph' are displayed underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  cumTS_inst=matrix(0,5,1)\n",
    "  # 10 values, the first one being 0 to associate to initial time\n",
    "  for (i in 1:4){QQ=(TS[i]+TS[i+1])*time_interval/2;cumTS_inst[i+1]=cumTS_inst[i]+QQ}\n",
    "  as.vector(cumTS_inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  It turns out that in R, there is a very smart and simple way to calculate cumulative flow, loads, etc. of a time series (TS here) using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  c(0,(cumsum(TS[-1])+cumsum(head(TS,-1)))/2)*time_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic comes the function `cumsum()` which calculates the cumulative sum of a vector and generates a vector of the same length of the original one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  TS\n",
    "  cumsum(TS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one can remove the ***first*** point of a time series, using the following code, and calculate the cumulative sum of this new vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  TS[-1]\n",
    "  cumsum(TS[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, one can remove the ***last*** point of a time series, using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " head(TS,-1)\n",
    "  cumsum(head(TS,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  and the fact that each trapeze is the average of two rectangles represented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  par(mar=c(4.5,4.5,0.5,0.5))\n",
    "  plot(x,TS,xlim=xlim,ylim=ylim)\n",
    "  suprectxy=cbind(0:4,rep(0,5),1:5,TS[2:6])\n",
    "  infrectxy=cbind(0:4,rep(0,5),1:5,TS[1:5])\n",
    "  for (i in 1:5){rect(infrectxy[i,1],infrectxy[i,2],infrectxy[i,3],infrectxy[i,4],col = transpblue)}\n",
    " for (i in 1:5){rect(suprectxy[i,1],suprectxy[i,2],suprectxy[i,3],suprectxy[i,4],col = transpred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Let us apply this method to the Maudouve hydrograph plotted earlier. Calculating the cumulative flow corresponds to integrating under the hydrograph curve, as represented by the grey area on the left panel. The corresponding cumulative flow, expressed in mm is plotted on the right side of the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  par(mfrow = c(3,2));par(mar=c(4.5,5,0.5,0.5))\n",
    "  options(repr.plot.width=12, repr.plot.height=12)\n",
    "  xlim = as.POSIXct(c(startdate,enddate))    \n",
    "      n=c(2500,4500,N)\n",
    "  for (i in 1:3){\n",
    "    plot(0,0,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=xlim,ylim=ylimQ)\n",
    "      abline(h=0)\n",
    "      axis.POSIXct(1, at=seq(startdate, enddate, by=\"month\"), format=\"%m/%d\",cex.axis=ScaleF)\n",
    "      axis(2,cex.axis=ScaleF)\n",
    "      polygon(c(D[1:n[i]],D[n[i]:1]),c(Q[1:n[i]],rep(0,n[i])),col=\"grey\")\n",
    "      par(new=TRUE)\n",
    "      plot(D,Q,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=xlim,ylim=ylimQ)\n",
    "      mtext(\"Dates in 1997-1998\",side=1,line=3,cex=ScaleF) # add in the margin the defined labels and title\n",
    "      mtext(y1lab,side=2,line=3,cex=ScaleF)\n",
    "          \n",
    "  cumQ=c(0,(cumsum(Q[-1])+cumsum(head(Q,-1)))/2)*3600/WSarea/1000 # calculates in mm the cumulative flow for each time stamp \n",
    "  \n",
    "  \n",
    "  plot(D[1:n[i]],cumQ[1:n[i]],col=\"red\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=xlim,ylim=c(0,cumQ[N]))\n",
    "      abline(h=0)\n",
    "      abline(h=seq(0,1000,by=50),lty=2,col=\"lightgrey\")\n",
    "      axis.POSIXct(1, at=seq(startdate, enddate, by=\"month\"), format=\"%m/%d\",cex.axis=ScaleF)\n",
    "      axis(2,cex.axis=ScaleF)\n",
    "      par(new=TRUE)\n",
    "      mtext(\"Dates in 1997-1998\",side=1,line=3,cex=ScaleF) # add in the margin the defined labels and title\n",
    "      mtext(\"Cumulative Flow volume (mm)\",side=2,line=3,cex=ScaleF)\n",
    "  }\n",
    "      \n",
    "    print(signif(max(cumQ),digits = 3)) # displays the final cumulative flow value in m3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Notice that  most of the increase of the cumulative flow occurs during the January and April periods described above.\n",
    "  \n",
    "### Evaluating the importance of rare high flow events: flow duration curves\n",
    "  \n",
    "#### Sorting flow and load values\n",
    "  \n",
    "  Flow occurs permanent streams throughout the year, but with bursts following rainfall events, which are, in most places on earth relatively rare. For example, in North Carolina, it rains about 7% of the time. Most of the flow occurs after these rare occurrences. The idea behind the ***duration curve*** concept is to characterize the importance of high flow events in the overall volume of water generated.\n",
    "  \n",
    "  Flow duration curves represent the percentage of the total flow that occurred in x% of the time corresponding to the highest flows. The same applies for loads. This might sound a bit murky, but hopefully it will not with the further explanations below. To get there, one first needs to order flow and loads in descending order. \n",
    "  <br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  QSort=sort(Q,decreasing = TRUE)   #Sorts instantaneous flow rates in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also calculate the cumulative flow associated with the sorted instantaneous flow rates as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  cumQSort<-c(0,(cumsum(QSort[-1])+cumsum(head(QSort,-1)))/2)*3600/WSarea/1000\n",
    "  cumQSortPerc<-cumQSort/tail(cumQSort,1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The blue hydrograph from above now becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  par(mar=c(4.5,4.5,1,1)) \n",
    "  plot(1:length(QSort),QSort,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",ylim=ylimQ)\n",
    "  abline(h=0)    \n",
    "  axis(2,cex.axis=ScaleF)   \n",
    "  mtext(y1lab,side=2,line=3,cex=ScaleF)\n",
    "  mtext(\"Cumulative number of flow values\",side=1,line=3,cex=ScaleF)\n",
    "  legend(\"topright\",c(\"Sorted Flow\"),lty = c(1), col = c(\"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now the cumulative flow volume curve corresponding to the highest flow rates as a function, not of time anymore but of the cumulative number of flow values looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  par(mar=c(4.5,5.5,1,1)) \n",
    "  plot(cumQSortPerc,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\", ylim=c(0,100))\n",
    "  abline(h=0)    \n",
    "  axis(2,cex.axis=ScaleF)\n",
    "  mtext(\"Cumulative number of flow values\",side=1,line=1,cex=ScaleF)\n",
    "  mtext(\"%age of cumulative flow corresponding to\\n the highest sorted flow rates \",side=2,line=3,cex=ScaleF)\n",
    "   # the \\n in the text allows for line break in the title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to the integration under the curve of the sorted hydrograph as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  par(mfrow = c(3,2));par(mar=c(4.5,5,0.5,0.5))\n",
    "  options(repr.plot.width=12, repr.plot.height=12)\n",
    "  xlim = as.POSIXct(c(startdate,enddate))    \n",
    "      n=c(2500,4500,N)\n",
    "  for (i in 1:3){\n",
    "    plot(0,0,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=c(1,length(Q)),ylim=ylimQ)\n",
    "      abline(h=0)\n",
    "      axis(2,cex.axis=ScaleF)\n",
    "      polygon(c(1:n[i],n[i]:1),c(QSort[1:n[i]],rep(0,n[i])),col=\"grey\")\n",
    "      par(new=TRUE)\n",
    "      plot(1:length(QSort),QSort,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=c(1,length(Q)),ylim=ylimQ)\n",
    "      mtext(y1lab,side=2,line=3,cex=ScaleF)\n",
    "          \n",
    "  plot(1:n[i],cumQSort[1:n[i]],col=\"red\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=c(1,length(Q)),ylim=c(0,cumQ[N]))\n",
    "      abline(h=0)\n",
    "      abline(h=seq(0,1000,by=50),lty=2,col=\"lightgrey\")\n",
    "      axis(2,cex.axis=ScaleF)\n",
    "      par(new=TRUE)\n",
    "      mtext(\"Cumulative Flow volume (mm)\",side=2,line=3,cex=ScaleF)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Notice that the cumulative sorted flow curve does not have the two large increases observed for the months of January and April anymore because all flows are sorted in decreasing order, regardless of when they occurred. \n",
    "  \n",
    "  Notice that there is still no unit added for the x axis because I decided that the cumulative number of flow value does not really add a lot to the analysis.  However, it becomes very interesting to transform these values in probability of occurrence. Each value has 1/N the probability to occur. We can also calculate the cumulative probability of occurrence of flow values.  Flow and load duration curves are thus derived this way.\n",
    "  \n",
    "### Flow duration curves as flow exceedance curves\n",
    "  \n",
    "  The previous curves give the semi-continuous duration curves. In practice, we like to use discrete values or percentages to express ourselves. In other words, to characterize the importance of high flow in the generation of flow volume in a watershed, we like to say something like \"50% of the flow in that watershed occurred in 10% of the time, corresponding to the highest flow\". This provides a way of demonstrating of how relatively flashy the watershed may be, either relatively to other watersheds or to previous years.\n",
    "  \n",
    "  The flashiness of a watershed refers to how rapidly flow is altered as a result of storm events/varying conditions.  More frequent spikes in flow in response to precipitation events, in which flow increases and decreases more greatly and rapidly, are typically indicative of watersheds with predominant portions of streamflow being influenced by surface runoff, a quicker responding contributor of water to streamflow.  \n",
    "  \n",
    "  Practically, one can associate to each cumulative sorted discharge value a percentage of the total discharge yielding W~k%~ values (W for Water volume) corresponding to the k^th^ cumulative probability of the time elapsed, with k being an integer. This corresponds to discretize the continuous curves above to 100 points. \n",
    "  \n",
    "  Practically this can be calculated like this:   \n",
    "  <br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  Wk=quantile(cumQSort,probs=seq(0.01,1,0.01))/tail(cumQSort,1) #Calculates and assigns Wk% values to a probability occurring in 1-100% of the total time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the discretized flow duration curve is illustrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      xlim=c(0,100);ylim=c(0,100);\n",
    "      plot(1:100,Wk*100,xlab=\"Prob of Occurrence %\",ylab=\"Mk% & Wk%\",xlim=xlim,ylim=ylim,pch=21,col=\"black\",bg=\"blue\")\n",
    "      par(new=TRUE)\n",
    "    #  plot(1:100,Mk*100,xlab=\"Prob of Occurrence %\",ylab=\"Mk% & Wk%\",xlim=xlim,ylim=ylim,pch=22,col=\"black\",bg=ColElmt)\n",
    "    #  par(new=TRUE)\n",
    "      abline(1,1,col=\"black\",lty=\"dashed\",xlim=xlim,ylim=ylim)\n",
    "      par(new=TRUE)\n",
    "      legend(\"bottomright\",c(\"Cumul Q\",\"Cumul NO3 load\"),\n",
    "            pch=c(19),\n",
    "            col=c(\"blue\"),\n",
    "            bg=\"white\")\n",
    "      title(main=\"Nitrate Load and flow duration curves\") # the \\n in the text allows for line break in the title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  One can then easily report that, for example, in 10% of the time corresponding to the highest flows, `r signif(Wk[10]*100,digits = 2)`% of the flow occurred using this `signif(Wk[10]*100,digits = 2)`% code. This watershed is thus relatively flashy as about 41% of its total flow volume occurs in 10% of the time.\n",
    "  \n",
    "  Now, the interesting part of the curve is what happens for the low probability of occurrence because in this analysis, it corresponds to the highest flow. When one adds several curves on the same graph, it become difficult to distinguish the curves together. One way around that is to use a 'qnorm scale' of the same graph using the code below. This gives visual importance to the low and high percentage values, and this is exactly what we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      #Code for plotting the double cumulative plot using the normal distribution probabilities to zoom in on the lower and upper tails\n",
    "      SelectPerc<-c(1,2,3,5,10,25,50,75,90,95,97,98,99,100) # SelectPerc is a set of user defined values of percentages of the total time to be used for calculating and plotting specific corresponding Wk% (and Mk% values)\n",
    " \n",
    "      qnormSelectPerc<-qnorm(SelectPerc/100) #All this does is transforming the selected values chosen in SelectPerc (divided by 100 to express them as percentage values) such that in the plotting, the tail ends of the values be highlighed. Technically, the qnorm function takes a given probability (x values in this case) and returns the corresponding cumulative distribution value (Z-score) based on a normal distribution curve   \n",
    "  \n",
    "      qnormWk<-qnorm(Wk[SelectPerc]) #This does the same thing here with the Wk values corresponding with percentages of the total time defined by values in SelectPerc. Technically the qnorm function takes percentages of the flow occurring associated with percentages of the total time defined by SelectPerc values and assigns Z-score values to each probability based on the normal distribution curve \n",
    "\n",
    "      color<-c(\"blue\") #Defines the plot colors for the Wk\n",
    "\n",
    "      plot(qnormSelectPerc,qnormWk,xlab=\"Probability of Occurrence (%)\",ylab=\"Wk%\",\n",
    "           type=\"o\",xaxt=\"n\",yaxt=\"n\",xlim=c(-2.5,2.5),ylim=c(-2.5,2.5),pch=19,col=color) #Plots the qnorm transformed values of Wk as a function of qnorm transformed values of the selected percentage values. The option xaxt=\"n\",yaxt=\"n\" tell R that none of the axis ticks and tick labels should be plotted at this point.\n",
    "      par(new=TRUE)\n",
    "  \n",
    "      \n",
    "      axis(1,at=qnormSelectPerc,labels=SelectPerc) # This adds the axis ticks and numbers that were not plotted above at specified values (qnormSelectPerc) and the labels shown are SelectPerc\n",
    "      axis(2,at=qnormSelectPerc,labels=SelectPerc) # same as above\n",
    "      title(main=\"Double cumulative probability plot for flow volume\") # the \\n in the text allows for line break in the title\n",
    "      abline(h=qnormSelectPerc,lty=3,col=\"grey\") #Plots horizontal gridlines at the same given values\n",
    "      abline(v=qnormSelectPerc,lty=3,col=\"grey\") #Plots vertical gridlines at the same given values\n",
    "      legend(\"bottomright\",c(\"Cumul Q\"),\n",
    "            pch=1,\n",
    "            col=color,\n",
    "            bg=\"white\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chemographs and concentration levels\n",
    "  \n",
    "  With rapid changes in flow during events, concentrations vary just as well. This has remained pretty much hidden to most people until the 1980s because there was no easy way to measure water quality at the pace at which flow rates were measured. Since then instruments have been able to capture concentrations at a pace equal or close to that of flow monitoring. \n",
    "  \n",
    "  The curve that plots the variations of concentrations with flow is referred to as a ***chemograph***. The nitrate annual chemograph for the Maudouve watershed presented above is illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  data<-read.csv(file=\"sample_1hr_QC_data.csv\",header = TRUE) #Reads file into table format\n",
    "  options(repr.plot.width=12, repr.plot.height=8)\n",
    "  WSarea<-24.2 #Area of watershed in km2\n",
    "  WS<-\"Maudouve at Saint-Donan, France\"\n",
    "  names(data)=c(\"datetime\",\"Q\",\"C\")   # renames the columns in simpler names\n",
    "  data<-as.data.frame(data)\n",
    "  data$datetime<-as.POSIXct(strptime(data$datetime, \"%Y-%m-%d %H:%M:%S\")) # transforms characters into date values understood by R\n",
    "  D<-data$datetime\n",
    "  Q<-data$Q   #Defines Q as the flow value (m3/s)\n",
    "  C<-data$C   #Defines C as the Concentration value (mg NO3-N/L)\n",
    "  L<-Q*C # Calculates the load in grams\n",
    "  N=nrow(data)   #Sets N to the value equal to the number of total rows in the table\n",
    "  startdate<-D[1]\n",
    "  enddate<-D[N]\n",
    "  \n",
    "  # definition of the x and y axes limits\n",
    "  xlim = as.POSIXct(c(startdate,enddate))  # this renders the first and last date understandable for plotting purposes\n",
    "  ylimQ = c(0,max(Q))           # ylim for flow\n",
    "  ylimC = c(0,max(C))           # ylim for concentrations\n",
    "      \n",
    "  ScaleF = 1.2                  # scaling factor for size of fonts and other things\n",
    "      \n",
    "  y1lab<-expression(\"Flow rate (\" * m^3 * \"/s)\")  # defines the label for flow\n",
    "  y2lab<-substitute(paste(\"Nitrate concentration (mg \",NO[x]^{y},\"-N)\",sep=\"\"),list(x=3,y=\"-\")) # defines the label for concentrations\n",
    "  \n",
    "  par(mar=c(4.5,4.5,4,4.5))     # defines the sizes, in number of lines, for the margins (bottom, left, top, right)\n",
    "  \n",
    "      ltyp=c(1,2)\n",
    "      \n",
    "      plot(D,Q,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=xlim,ylim=ylimQ)\n",
    "      # we are taking all the default addition of axis tick marks and numbers out by using xaxt and yaxt = \"n\"\n",
    "      # and setting the axis labels at nothing using xlab = \"\" and ylab = \"\"\n",
    "      \n",
    "      abline(h=0)\n",
    "      abline(v=seq(startdate, enddate, by=\"week\"),col=(\"grey\"))\n",
    "      axis.POSIXct(1, at=seq(startdate, enddate, by=\"month\"), format=\"%m/%d\",cex.axis=ScaleF)\n",
    "      # this tells R that we want the X axis ticks and values to be displayed as dates, be added on a monthly basis,\n",
    "      # using the month/day format\n",
    "      axis(2,cex.axis=ScaleF)\n",
    "      # this tells R that the first Y axis ticks can be displayed  (that function was repressed earlier by 'yaxt=\"n\" ')\n",
    "      par(new=TRUE)\n",
    "      # this tells R that a new plot has already been opened, in other words you are telling R to keep adding things\n",
    "      # on the existing plot\n",
    "      \n",
    "      ColElmt=\"deeppink1\"\n",
    "      plot(D,C,col=ColElmt,type=\"l\",cex=0.1,yaxt=\"n\",\n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=xlim,ylim=ylimC)\n",
    "      # plots the concentration data\n",
    "      axis(4,cex.axis=ScaleF)\n",
    "      # this tells R that the second Y axis ticks can be displayed (that function was repressed earlier by 'yaxt=\"n\" ')\n",
    "      par(new=TRUE)\n",
    "      \n",
    "      mtext(\"Dates in 1997-1998\",side=1,line=3,cex=ScaleF) # add in the margin the defined labels and title\n",
    "      mtext(y1lab,side=2,line=3,cex=ScaleF)\n",
    "      mtext(y2lab,side=4,line=3,cex=ScaleF)\n",
    "      mtext(WS,side=3,line=1.5,cex=ScaleF)\n",
    "      \n",
    "      legend(\"topleft\",c(\"Flow\",\"Conc\"),lty = c(1,1), col = c(\"blue\",ColElmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zooming around one event illustrates some of important characteristics of chemographs, which may vary depending on the pollutant of concern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  data<-read.csv(file=\"sample_1hr_QC_data.csv\",header = TRUE) #Reads file into table format\n",
    "  \n",
    "  WSarea<-24.2 #Area of watershed in km2\n",
    "  WS<-\"Maudouve at Saint-Donan, France\"\n",
    "  names(data)=c(\"datetime\",\"Q\",\"C\")   # renames the columns in simpler names\n",
    "  data<-as.data.frame(data)\n",
    "  data$datetime<-as.POSIXct(strptime(data$datetime, \"%Y-%m-%d %H:%M:%S\")) # transforms characters into date values understood by R\n",
    "  startdate<-as.POSIXct(\"1998-07-04 00:00:00\")\n",
    "  enddate<-as.POSIXct(\"1998-07-08 00:00:00\")\n",
    "  subdata<-subset(data,data$datetime>=startdate & data$datetime<=enddate)\n",
    "  data<-subdata\n",
    "  D<-data$datetime\n",
    "  Q<-data$Q   #Defines Q as the flow value (m3/s)\n",
    "  C<-data$C   #Defines C as the Concentration value (mg NO3-N/L)\n",
    "  L<-Q*C # Calculates the load in g/s\n",
    "  N=nrow(data)   #Sets N to the value equal to the number of total rows in the table\n",
    "  \n",
    "  \n",
    "  # definition of the x and y axes limits\n",
    "  xlim = as.POSIXct(c(startdate,enddate))  # this renders the first and last date understandable for plotting purposes\n",
    "  ylimQ = c(0,max(Q))           # ylim for flow\n",
    "  ylimC = c(0,max(C))           # ylim for concentrations\n",
    "      \n",
    "  ScaleF = 1.2                  # scaling factor for size of fonts and other things\n",
    "      \n",
    "  y1lab<-expression(\"Flow rate (\" * m^3 * \"/s)\")  # defines the label for flow\n",
    "  y2lab<-substitute(paste(\"Nitrate concentration (mg \",NO[x]^{y},\"-N)\",sep=\"\"),list(x=3,y=\"-\")) # defines the label for concentrations\n",
    "  \n",
    "  par(mar=c(4.5,4.5,4,4.5))     # defines the sizes, in number of lines, for the margins (bottom, left, top, right)\n",
    "  \n",
    "      ltyp=c(1,2)\n",
    "      \n",
    "      plot(D,Q,col=\"blue\",type=\"l\",cex=0.1,yaxt=\"n\",     \n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=xlim,ylim=ylimQ)\n",
    "      # we are taking all the default addition of axis tick marks and numbers out by using xaxt and yaxt = \"n\"\n",
    "      # and setting the axis labels at nothing using xlab = \"\" and ylab = \"\"\n",
    "      \n",
    "      abline(h=0)\n",
    "      abline(v=seq(startdate, enddate, by=\"day\"),col=(\"grey\"))\n",
    "      axis.POSIXct(1, at=seq(startdate, enddate, by=\"day\"), format=\"%m/%d\",cex.axis=ScaleF)\n",
    "      # this tells R that we want the X axis ticks and values to be displayed as dates, be added on a monthly basis,\n",
    "      # using the month/day format\n",
    "      axis(2,cex.axis=ScaleF)\n",
    "      # this tells R that the first Y axis ticks can be displayed  (that function was repressed earlier by 'yaxt=\"n\" ')\n",
    "      par(new=TRUE)\n",
    "      # this tells R that a new plot has already been opened, in other words you are telling R to keep adding things\n",
    "      # on the existing plot\n",
    "      \n",
    "      ColElmt=\"deeppink1\"\n",
    "      plot(D,C,col=ColElmt,type=\"l\",cex=0.1,yaxt=\"n\",\n",
    "           lty=ltyp[1],xaxt=\"n\",xlab=\"\",ylab=\"\",xlim=xlim,ylim=ylimC)\n",
    "      # plots the concentration data\n",
    "      axis(4,cex.axis=ScaleF)\n",
    "      # this tells R that the second Y axis ticks can be displayed (that function was repressed earlier by 'yaxt=\"n\" ')\n",
    "      par(new=TRUE)\n",
    "      \n",
    "      mtext(\"Dates in 1997-1998\",side=1,line=3,cex=ScaleF) # add in the margin the defined labels and title\n",
    "      mtext(y1lab,side=2,line=3,cex=ScaleF)\n",
    "      mtext(y2lab,side=4,line=3,cex=ScaleF)\n",
    "      mtext(WS,side=3,line=1.5,cex=ScaleF)\n",
    "      \n",
    "      legend(\"right\",c(\"Flow\",\"Conc\"),lty = c(1,1), col = c(\"blue\",ColElmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  One can see that the concentration of nitrate in this example is not constant! It varies opposite to flow variations, with the concentrations appearing relatively all the more diluted that flow is high. This is referred to as a ***dilution effect***.\n",
    "  \n",
    "  Let us pause for a second and find other indicators of concentration over that the hydrograph period. It is easy to calculate the average or the median concentration over the four days selected here. The arithmetic average concentration can be calculated in the text using `signif(mean(C),3)`, which yields `r signif(mean(C),3)` mg N/L. Similarly the median concentration is `r signif(median(C),3)` mg N/L. These values are about three times the nitrate concentration values that I ask you to remember for most agricultural water: 5 mg N/L. This is because Brittany in France is a very intensive agricultural area where the denitrification capacities in watersheds are not quite as high as those observed in North Carolina for example.\n",
    "  \n",
    "  The level of concentration does give the general pollution level. But more interestingly, it allows to calculate ***pollutant loads***, or the mass of pollutants that flows by a particular station. ***Instantaneous loads*** correspond to the mass of pollutant flowing per unit time at a station and its dimensions are [M.T^-1^]. Instantaneous loads for pollutants are the equivalent of flow rates for water. They are calculated as the product of flow by concentrations\n",
    "  \n",
    "  \\[\n",
    "  L(t) = Q(t).C(t)\n",
    "  \\]\n",
    "  \n",
    "  ***Cumulative loads*** correspond to the cumulative mass of pollutants that has flowed by a station over a given period of time, and are the equivalent of cumulative flow volume for water. \n",
    "  \n",
    "  \\[\n",
    "  CumulLoad = \\int_{}^{period}{L(t).dt} = \\int_{}^{period}{Q(t).C(t).dt}\n",
    "  \\]\n",
    "  \n",
    "  One can calculate the cumulative load of nitrate over the three days of record above using the following code:\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  cumulLoad<-c(0,(cumsum(L[-1])+cumsum(head(L,-1)))/2)*3600/1000\n",
    "  tail(cumulLoad,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  So this means that over these 4 days, 839 kg N were discharged at that particular station. That is quite a bit!!\n",
    "  \n",
    "  In most stations around the world, however, to this day, researchers and water agencies do not have access to the continuous chemograph, but they are still trying to calculate loads. Because most stations do have continuous water flow measurements, one can use this information to calculate loads. Technically, the load calculated above for these 4 days can be calculated by multiplying the flow volume over these four days by the ***flow-weighted concentration*** (FWC) value. \n",
    "  \n",
    "  FWC in our example can be calculated as:\n",
    "  \n",
    "  $FWC = \\frac{CumulLoad}{CumulQ}$\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  cumulQ<-c(0,(cumsum(Q[-1])+cumsum(head(Q,-1)))/2)*3600/1000\n",
    "  FWC<-tail(cumulLoad,1)/tail(cumulQ,1)\n",
    "  FWC\n",
    "  arithmean<-signif(mean(C)*tail(cumulQ,1),3);arithmean\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The FWC in our case here is 12.9 mg N/L, which quite a bit lower than the arithmetic average. This is expected as during the highest flows, the concentrations tend to be diluted. \n",
    "  \n",
    "  But in reality, people do not have access to the FWC, so one has to best estimate concentration. There are many different ways, all of which wrong, to estimate these FWC. One is to use the arithmetic average concentration as an estimate. By doing so, one obtains for an estimate of the load over this period using `signif(mean(C)*tail(cumulQ,1),3)`, i.e., `r signif(mean(C)*tail(cumulQ,1),3)` kg, that is `r signif((mean(C)*tail(cumulQ,1)-tail(cumulLoad,1))/tail(cumulLoad,1)*100,2)`% more than the actual one. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
